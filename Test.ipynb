{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinEcone12/NS_NN/blob/main/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7JUO9QywmSL1",
        "outputId": "9dfbc03a-040a-4da5-d760-dce3ce78f535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Name     J     L   Ksym       Qsym    nccu    nccl      Pccu      Pccl  \\\n",
            "0  nm_skins  26.0  43.5   98.8  2863.8810  0.0815  0.0865  0.050053  0.078606   \n",
            "1  nm_skins  26.1  44.7 -106.1   675.1560  0.0745  0.0835  0.230331  0.324708   \n",
            "2  nm_skins  26.1  60.5   10.4   901.0016  0.0675  0.0755  0.140935  0.217652   \n",
            "3  nm_skins  26.2  53.1 -106.4   166.2228  0.0685  0.0785  0.215581  0.331853   \n",
            "4  nm_skins  26.3  46.2   79.2  2547.4890  0.0795  0.0845  0.085677  0.117963   \n",
            "\n",
            "      muccu  ...   Ksym11    Qsym11      S24       L24    Ksym24     Qsym24  \\\n",
            "0  7.268751  ... -25.6129  723.0624  36.2438  115.4890  562.6525  1969.1892   \n",
            "1  7.645290  ... -72.2965  196.0169  32.6206   44.9355 -168.3113   477.7477   \n",
            "2  5.390887  ... -20.1886  250.4006  37.3772  102.8839  132.2338   631.6435   \n",
            "3  6.343669  ... -59.6719   73.4657  34.0642   54.0167 -226.5078   130.9504   \n",
            "4  7.456027  ... -27.3923  646.8752  36.6176  111.9252  480.6416  1753.5933   \n",
            "\n",
            "    drPb208    alPb208    drCa48    alCa48  \n",
            "0  0.086985  21.591232  0.122933  2.439818  \n",
            "1  0.137616  24.656562  0.153171  2.863743  \n",
            "2  0.144207  25.872589  0.155641  2.995773  \n",
            "3  0.158230  26.296632  0.164239  3.073342  \n",
            "4  0.099850  22.087979  0.130290  2.509069  \n",
            "\n",
            "[5 rows x 37 columns]\n",
            "Index(['Name', 'J', 'L', 'Ksym', 'Qsym', 'nccu', 'nccl', 'Pccu', 'Pccl',\n",
            "       'muccu', 'muccl', 'yccu', 'yccl', 'S6', 'L6', 'Ksym6', 'Qsym6', 'S8',\n",
            "       'L8', 'Ksym8', 'Qsym8', 'S10', 'L10', 'Ksym10', 'Qsym10', 'S11', 'L11',\n",
            "       'Ksym11', 'Qsym11', 'S24', 'L24', 'Ksym24', 'Qsym24', 'drPb208',\n",
            "       'alPb208', 'drCa48', 'alCa48'],\n",
            "      dtype='object')\n",
            "Feature matrix (x_train): (516, 3)\n",
            "Target matrix (y_train): (516,)\n",
            "Feature matrix (x_test): (130, 3)\n",
            "Target matrix (y_test): (130,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - loss: 1.5419 - mae: 0.9921 - val_loss: 0.0191 - val_mae: 0.1245 - learning_rate: 0.0010\n",
            "Epoch 2/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0677 - mae: 0.8030 - val_loss: 0.0116 - val_mae: 0.0966 - learning_rate: 0.0010\n",
            "Epoch 3/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8700 - mae: 0.7057 - val_loss: 0.0088 - val_mae: 0.0814 - learning_rate: 0.0010\n",
            "Epoch 4/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6659 - mae: 0.6319 - val_loss: 0.0053 - val_mae: 0.0604 - learning_rate: 0.0010\n",
            "Epoch 5/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5683 - mae: 0.5787 - val_loss: 0.0043 - val_mae: 0.0540 - learning_rate: 0.0010\n",
            "Epoch 6/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5221 - mae: 0.5598 - val_loss: 0.0048 - val_mae: 0.0569 - learning_rate: 0.0010\n",
            "Epoch 7/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4804 - mae: 0.5295 - val_loss: 0.0058 - val_mae: 0.0624 - learning_rate: 0.0010\n",
            "Epoch 8/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4593 - mae: 0.5258 - val_loss: 0.0065 - val_mae: 0.0656 - learning_rate: 0.0010\n",
            "Epoch 9/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4373 - mae: 0.5175 - val_loss: 0.0064 - val_mae: 0.0646 - learning_rate: 0.0010\n",
            "Epoch 10/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4492 - mae: 0.5115 - val_loss: 0.0057 - val_mae: 0.0605 - learning_rate: 0.0010\n",
            "Epoch 11/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3425 - mae: 0.4509 - val_loss: 0.0055 - val_mae: 0.0590 - learning_rate: 0.0010\n",
            "Epoch 12/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3279 - mae: 0.4384 - val_loss: 0.0059 - val_mae: 0.0603 - learning_rate: 0.0010\n",
            "Epoch 13/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3002 - mae: 0.4323 - val_loss: 0.0059 - val_mae: 0.0599 - learning_rate: 0.0010\n",
            "Epoch 14/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3458 - mae: 0.4443 - val_loss: 0.0062 - val_mae: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 15/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3710 - mae: 0.4490 - val_loss: 0.0065 - val_mae: 0.0619 - learning_rate: 0.0010\n",
            "Epoch 16/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3058 - mae: 0.4175 - val_loss: 0.0061 - val_mae: 0.0595 - learning_rate: 0.0010\n",
            "Epoch 17/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3144 - mae: 0.4258 - val_loss: 0.0052 - val_mae: 0.0557 - learning_rate: 0.0010\n",
            "Epoch 18/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2445 - mae: 0.3803 - val_loss: 0.0049 - val_mae: 0.0548 - learning_rate: 0.0010\n",
            "Epoch 19/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2393 - mae: 0.3645 - val_loss: 0.0044 - val_mae: 0.0519 - learning_rate: 0.0010\n",
            "Epoch 20/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2720 - mae: 0.3852 - val_loss: 0.0040 - val_mae: 0.0494 - learning_rate: 0.0010\n",
            "Epoch 21/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2423 - mae: 0.3661 - val_loss: 0.0039 - val_mae: 0.0492 - learning_rate: 0.0010\n",
            "Epoch 22/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2072 - mae: 0.3488 - val_loss: 0.0043 - val_mae: 0.0521 - learning_rate: 0.0010\n",
            "Epoch 23/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2303 - mae: 0.3626 - val_loss: 0.0048 - val_mae: 0.0549 - learning_rate: 0.0010\n",
            "Epoch 24/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2218 - mae: 0.3603 - val_loss: 0.0049 - val_mae: 0.0548 - learning_rate: 0.0010\n",
            "Epoch 25/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2146 - mae: 0.3623 - val_loss: 0.0047 - val_mae: 0.0537 - learning_rate: 0.0010\n",
            "Epoch 26/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1545 - mae: 0.2944 - val_loss: 0.0047 - val_mae: 0.0540 - learning_rate: 0.0010\n",
            "Epoch 27/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2002 - mae: 0.3429 - val_loss: 0.0048 - val_mae: 0.0542 - learning_rate: 0.0010\n",
            "Epoch 28/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1961 - mae: 0.3339 - val_loss: 0.0046 - val_mae: 0.0528 - learning_rate: 0.0010\n",
            "Epoch 29/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2110 - mae: 0.3464 - val_loss: 0.0046 - val_mae: 0.0526 - learning_rate: 0.0010\n",
            "Epoch 30/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2138 - mae: 0.3365 - val_loss: 0.0046 - val_mae: 0.0529 - learning_rate: 0.0010\n",
            "Epoch 31/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1778 - mae: 0.3272 - val_loss: 0.0047 - val_mae: 0.0542 - learning_rate: 0.0010\n",
            "Epoch 32/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2009 - mae: 0.3240 - val_loss: 0.0046 - val_mae: 0.0544 - learning_rate: 0.0010\n",
            "Epoch 33/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1928 - mae: 0.3276 - val_loss: 0.0044 - val_mae: 0.0536 - learning_rate: 0.0010\n",
            "Epoch 34/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1712 - mae: 0.3072 - val_loss: 0.0043 - val_mae: 0.0530 - learning_rate: 0.0010\n",
            "Epoch 35/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1621 - mae: 0.3094 - val_loss: 0.0042 - val_mae: 0.0523 - learning_rate: 0.0010\n",
            "Epoch 36/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1798 - mae: 0.3175 - val_loss: 0.0038 - val_mae: 0.0494 - learning_rate: 0.0010\n",
            "Epoch 37/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1550 - mae: 0.2922 - val_loss: 0.0034 - val_mae: 0.0468 - learning_rate: 0.0010\n",
            "Epoch 38/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1532 - mae: 0.3043 - val_loss: 0.0033 - val_mae: 0.0458 - learning_rate: 0.0010\n",
            "Epoch 39/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1375 - mae: 0.2810 - val_loss: 0.0031 - val_mae: 0.0447 - learning_rate: 0.0010\n",
            "Epoch 40/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1336 - mae: 0.2735 - val_loss: 0.0030 - val_mae: 0.0443 - learning_rate: 0.0010\n",
            "Epoch 41/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1259 - mae: 0.2846 - val_loss: 0.0027 - val_mae: 0.0420 - learning_rate: 0.0010\n",
            "Epoch 42/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1413 - mae: 0.2868 - val_loss: 0.0026 - val_mae: 0.0408 - learning_rate: 0.0010\n",
            "Epoch 43/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1163 - mae: 0.2559 - val_loss: 0.0026 - val_mae: 0.0411 - learning_rate: 0.0010\n",
            "Epoch 44/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1169 - mae: 0.2586 - val_loss: 0.0024 - val_mae: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 45/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0993 - mae: 0.2448 - val_loss: 0.0024 - val_mae: 0.0388 - learning_rate: 0.0010\n",
            "Epoch 46/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1131 - mae: 0.2449 - val_loss: 0.0022 - val_mae: 0.0375 - learning_rate: 0.0010\n",
            "Epoch 47/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0950 - mae: 0.2377 - val_loss: 0.0021 - val_mae: 0.0364 - learning_rate: 0.0010\n",
            "Epoch 48/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0996 - mae: 0.2452 - val_loss: 0.0020 - val_mae: 0.0355 - learning_rate: 0.0010\n",
            "Epoch 49/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1042 - mae: 0.2432 - val_loss: 0.0020 - val_mae: 0.0354 - learning_rate: 0.0010\n",
            "Epoch 50/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1032 - mae: 0.2448 - val_loss: 0.0021 - val_mae: 0.0365 - learning_rate: 0.0010\n",
            "Epoch 51/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0961 - mae: 0.2360 - val_loss: 0.0022 - val_mae: 0.0362 - learning_rate: 0.0010\n",
            "Epoch 52/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0907 - mae: 0.2177 - val_loss: 0.0022 - val_mae: 0.0365 - learning_rate: 0.0010\n",
            "Epoch 53/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1144 - mae: 0.2427 - val_loss: 0.0022 - val_mae: 0.0364 - learning_rate: 0.0010\n",
            "Epoch 54/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0986 - mae: 0.2348 - val_loss: 0.0021 - val_mae: 0.0355 - learning_rate: 0.0010\n",
            "Epoch 55/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0817 - mae: 0.2119 - val_loss: 0.0021 - val_mae: 0.0360 - learning_rate: 0.0010\n",
            "Epoch 56/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0861 - mae: 0.2200 - val_loss: 0.0020 - val_mae: 0.0354 - learning_rate: 0.0010\n",
            "Epoch 57/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0699 - mae: 0.2043 - val_loss: 0.0019 - val_mae: 0.0352 - learning_rate: 0.0010\n",
            "Epoch 58/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0720 - mae: 0.1962 - val_loss: 0.0018 - val_mae: 0.0350 - learning_rate: 0.0010\n",
            "Epoch 59/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0735 - mae: 0.2082 - val_loss: 0.0016 - val_mae: 0.0332 - learning_rate: 0.0010\n",
            "Epoch 60/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0797 - mae: 0.2083 - val_loss: 0.0015 - val_mae: 0.0317 - learning_rate: 0.0010\n",
            "Epoch 61/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0596 - mae: 0.1900 - val_loss: 0.0014 - val_mae: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 62/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0783 - mae: 0.2029 - val_loss: 0.0012 - val_mae: 0.0280 - learning_rate: 0.0010\n",
            "Epoch 63/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0703 - mae: 0.1968 - val_loss: 0.0012 - val_mae: 0.0268 - learning_rate: 0.0010\n",
            "Epoch 64/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0642 - mae: 0.1905 - val_loss: 0.0011 - val_mae: 0.0260 - learning_rate: 0.0010\n",
            "Epoch 65/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0586 - mae: 0.1834 - val_loss: 0.0012 - val_mae: 0.0272 - learning_rate: 0.0010\n",
            "Epoch 66/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0559 - mae: 0.1820 - val_loss: 0.0012 - val_mae: 0.0281 - learning_rate: 0.0010\n",
            "Epoch 67/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0568 - mae: 0.1863 - val_loss: 0.0012 - val_mae: 0.0283 - learning_rate: 0.0010\n",
            "Epoch 68/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0549 - mae: 0.1754 - val_loss: 0.0012 - val_mae: 0.0288 - learning_rate: 0.0010\n",
            "Epoch 69/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0512 - mae: 0.1649 - val_loss: 0.0011 - val_mae: 0.0274 - learning_rate: 0.0010\n",
            "Epoch 70/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0765 - mae: 0.1977 - val_loss: 0.0010 - val_mae: 0.0260 - learning_rate: 0.0010\n",
            "Epoch 71/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0527 - mae: 0.1726 - val_loss: 9.2522e-04 - val_mae: 0.0247 - learning_rate: 0.0010\n",
            "Epoch 72/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0454 - mae: 0.1601 - val_loss: 8.4349e-04 - val_mae: 0.0232 - learning_rate: 0.0010\n",
            "Epoch 73/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0512 - mae: 0.1628 - val_loss: 7.9309e-04 - val_mae: 0.0223 - learning_rate: 0.0010\n",
            "Epoch 74/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0483 - mae: 0.1636 - val_loss: 7.3986e-04 - val_mae: 0.0214 - learning_rate: 0.0010\n",
            "Epoch 75/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0495 - mae: 0.1701 - val_loss: 6.8231e-04 - val_mae: 0.0205 - learning_rate: 0.0010\n",
            "Epoch 76/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0434 - mae: 0.1543 - val_loss: 6.2690e-04 - val_mae: 0.0199 - learning_rate: 0.0010\n",
            "Epoch 77/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0504 - mae: 0.1668 - val_loss: 5.6905e-04 - val_mae: 0.0192 - learning_rate: 0.0010\n",
            "Epoch 78/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0366 - mae: 0.1476 - val_loss: 5.4603e-04 - val_mae: 0.0190 - learning_rate: 0.0010\n",
            "Epoch 79/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0388 - mae: 0.1517 - val_loss: 5.3219e-04 - val_mae: 0.0189 - learning_rate: 0.0010\n",
            "Epoch 80/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0362 - mae: 0.1396 - val_loss: 5.1021e-04 - val_mae: 0.0184 - learning_rate: 0.0010\n",
            "Epoch 81/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0351 - mae: 0.1346 - val_loss: 5.0699e-04 - val_mae: 0.0182 - learning_rate: 0.0010\n",
            "Epoch 82/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0359 - mae: 0.1431 - val_loss: 5.4648e-04 - val_mae: 0.0188 - learning_rate: 0.0010\n",
            "Epoch 83/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0329 - mae: 0.1342 - val_loss: 5.7187e-04 - val_mae: 0.0191 - learning_rate: 0.0010\n",
            "Epoch 84/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0381 - mae: 0.1432 - val_loss: 4.8735e-04 - val_mae: 0.0179 - learning_rate: 0.0010\n",
            "Epoch 85/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0393 - mae: 0.1427 - val_loss: 4.1870e-04 - val_mae: 0.0165 - learning_rate: 0.0010\n",
            "Epoch 86/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0327 - mae: 0.1393 - val_loss: 4.1741e-04 - val_mae: 0.0165 - learning_rate: 0.0010\n",
            "Epoch 87/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0260 - mae: 0.1203 - val_loss: 4.2042e-04 - val_mae: 0.0164 - learning_rate: 0.0010\n",
            "Epoch 88/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0341 - mae: 0.1332 - val_loss: 4.3378e-04 - val_mae: 0.0161 - learning_rate: 0.0010\n",
            "Epoch 89/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0312 - mae: 0.1329 - val_loss: 4.9770e-04 - val_mae: 0.0167 - learning_rate: 0.0010\n",
            "Epoch 90/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0381 - mae: 0.1400 - val_loss: 5.8365e-04 - val_mae: 0.0175 - learning_rate: 0.0010\n",
            "Epoch 91/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0276 - mae: 0.1196 - val_loss: 5.7430e-04 - val_mae: 0.0171 - learning_rate: 0.0010\n",
            "Epoch 92/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0283 - mae: 0.1205 - val_loss: 5.5807e-04 - val_mae: 0.0169 - learning_rate: 0.0010\n",
            "Epoch 93/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0267 - mae: 0.1217 - val_loss: 5.4194e-04 - val_mae: 0.0167 - learning_rate: 0.0010\n",
            "Epoch 94/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0257 - mae: 0.1169 - val_loss: 4.4886e-04 - val_mae: 0.0155 - learning_rate: 0.0010\n",
            "Epoch 95/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0246 - mae: 0.1129 - val_loss: 4.0046e-04 - val_mae: 0.0147 - learning_rate: 0.0010\n",
            "Epoch 96/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0193 - mae: 0.1040 - val_loss: 3.8988e-04 - val_mae: 0.0147 - learning_rate: 0.0010\n",
            "Epoch 97/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0241 - mae: 0.1157 - val_loss: 3.6539e-04 - val_mae: 0.0148 - learning_rate: 0.0010\n",
            "Epoch 98/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0189 - mae: 0.1014 - val_loss: 3.4539e-04 - val_mae: 0.0149 - learning_rate: 0.0010\n",
            "Epoch 99/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0214 - mae: 0.1070 - val_loss: 3.2348e-04 - val_mae: 0.0144 - learning_rate: 0.0010\n",
            "Epoch 100/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0259 - mae: 0.1115 - val_loss: 3.3111e-04 - val_mae: 0.0143 - learning_rate: 0.0010\n",
            "Epoch 101/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0194 - mae: 0.1071 - val_loss: 3.6018e-04 - val_mae: 0.0147 - learning_rate: 0.0010\n",
            "Epoch 102/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0174 - mae: 0.0960 - val_loss: 3.7355e-04 - val_mae: 0.0150 - learning_rate: 0.0010\n",
            "Epoch 103/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0178 - mae: 0.0996 - val_loss: 3.7307e-04 - val_mae: 0.0152 - learning_rate: 0.0010\n",
            "Epoch 104/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0211 - mae: 0.1044 - val_loss: 3.4234e-04 - val_mae: 0.0148 - learning_rate: 0.0010\n",
            "Epoch 105/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0200 - mae: 0.1050 - val_loss: 3.1798e-04 - val_mae: 0.0146 - learning_rate: 0.0010\n",
            "Epoch 106/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0195 - mae: 0.1002 - val_loss: 3.0172e-04 - val_mae: 0.0144 - learning_rate: 0.0010\n",
            "Epoch 107/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0179 - mae: 0.0990 - val_loss: 2.9057e-04 - val_mae: 0.0142 - learning_rate: 0.0010\n",
            "Epoch 108/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0140 - mae: 0.0908 - val_loss: 2.8846e-04 - val_mae: 0.0141 - learning_rate: 0.0010\n",
            "Epoch 109/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0161 - mae: 0.0919 - val_loss: 2.9946e-04 - val_mae: 0.0143 - learning_rate: 0.0010\n",
            "Epoch 110/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0135 - mae: 0.0881 - val_loss: 3.1318e-04 - val_mae: 0.0144 - learning_rate: 0.0010\n",
            "Epoch 111/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0158 - mae: 0.0955 - val_loss: 2.8708e-04 - val_mae: 0.0137 - learning_rate: 0.0010\n",
            "Epoch 112/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0143 - mae: 0.0904 - val_loss: 2.7412e-04 - val_mae: 0.0134 - learning_rate: 0.0010\n",
            "Epoch 113/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0159 - mae: 0.0942 - val_loss: 2.6961e-04 - val_mae: 0.0133 - learning_rate: 0.0010\n",
            "Epoch 114/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0147 - mae: 0.0884 - val_loss: 2.5235e-04 - val_mae: 0.0129 - learning_rate: 0.0010\n",
            "Epoch 115/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0134 - mae: 0.0871 - val_loss: 2.4489e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
            "Epoch 116/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0138 - mae: 0.0862 - val_loss: 2.5134e-04 - val_mae: 0.0130 - learning_rate: 0.0010\n",
            "Epoch 117/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0118 - mae: 0.0799 - val_loss: 2.4524e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
            "Epoch 118/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0132 - mae: 0.0821 - val_loss: 2.3675e-04 - val_mae: 0.0124 - learning_rate: 0.0010\n",
            "Epoch 119/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0135 - mae: 0.0852 - val_loss: 2.2875e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
            "Epoch 120/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0136 - mae: 0.0849 - val_loss: 2.2302e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
            "Epoch 121/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0117 - mae: 0.0801 - val_loss: 2.1916e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
            "Epoch 122/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0115 - mae: 0.0780 - val_loss: 2.1847e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 123/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0118 - mae: 0.0780 - val_loss: 2.2950e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
            "Epoch 124/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0091 - mae: 0.0708 - val_loss: 2.3675e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
            "Epoch 125/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0090 - mae: 0.0733 - val_loss: 2.2380e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 126/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0088 - mae: 0.0693 - val_loss: 2.2287e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 127/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0104 - mae: 0.0750 - val_loss: 2.0835e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 128/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0103 - mae: 0.0726 - val_loss: 2.1145e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 129/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0104 - mae: 0.0730 - val_loss: 2.2206e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 130/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0102 - mae: 0.0728 - val_loss: 2.6042e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 131/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0738 - val_loss: 2.9251e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
            "Epoch 132/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0100 - mae: 0.0720 - val_loss: 2.9899e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
            "Epoch 133/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0096 - mae: 0.0696 - val_loss: 2.8767e-04 - val_mae: 0.0126 - learning_rate: 0.0010\n",
            "Epoch 134/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0077 - mae: 0.0642 - val_loss: 2.5270e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 135/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0677 - val_loss: 2.4140e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 136/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0077 - mae: 0.0627 - val_loss: 2.5331e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 137/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0074 - mae: 0.0626 - val_loss: 2.6499e-04 - val_mae: 0.0123 - learning_rate: 0.0010\n",
            "Epoch 138/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0067 - mae: 0.0624 - val_loss: 2.6167e-04 - val_mae: 0.0124 - learning_rate: 0.0010\n",
            "Epoch 139/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0054 - mae: 0.0564 - val_loss: 2.5448e-04 - val_mae: 0.0126 - learning_rate: 0.0010\n",
            "Epoch 140/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0619 - val_loss: 2.4048e-04 - val_mae: 0.0124 - learning_rate: 0.0010\n",
            "Epoch 141/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0054 - mae: 0.0564 - val_loss: 2.3643e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 142/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0063 - mae: 0.0567 - val_loss: 2.4366e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
            "Epoch 143/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0063 - mae: 0.0579 - val_loss: 2.4730e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 144/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0066 - mae: 0.0571 - val_loss: 2.5020e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
            "Epoch 145/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0063 - mae: 0.0578 - val_loss: 2.4499e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
            "Epoch 146/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0059 - mae: 0.0561 - val_loss: 2.4692e-04 - val_mae: 0.0129 - learning_rate: 0.0010\n",
            "Epoch 147/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0055 - mae: 0.0539 - val_loss: 2.4968e-04 - val_mae: 0.0130 - learning_rate: 0.0010\n",
            "Epoch 148/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0523 - val_loss: 2.5206e-04 - val_mae: 0.0131 - learning_rate: 0.0010\n",
            "Epoch 149/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0055 - mae: 0.0533 - val_loss: 2.5396e-04 - val_mae: 0.0132 - learning_rate: 0.0010\n",
            "Epoch 150/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0038 - mae: 0.0461 - val_loss: 2.7203e-04 - val_mae: 0.0136 - learning_rate: 0.0010\n",
            "Epoch 151/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0051 - mae: 0.0497 - val_loss: 2.5468e-04 - val_mae: 0.0132 - learning_rate: 0.0010\n",
            "Epoch 152/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0050 - mae: 0.0542 - val_loss: 2.3415e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
            "Epoch 153/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0042 - mae: 0.0477 - val_loss: 2.2019e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
            "Epoch 154/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0047 - mae: 0.0518 - val_loss: 2.2003e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
            "Epoch 155/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0062 - mae: 0.0565 - val_loss: 2.2318e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 156/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0048 - mae: 0.0507 - val_loss: 2.2741e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 157/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0043 - mae: 0.0495 - val_loss: 2.3375e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 158/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0042 - mae: 0.0471 - val_loss: 2.4192e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
            "Epoch 159/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0036 - mae: 0.0459 - val_loss: 2.4622e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
            "Epoch 160/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0038 - mae: 0.0437 - val_loss: 2.3717e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
            "Epoch 161/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0433 - val_loss: 2.3078e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 162/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0036 - mae: 0.0429 - val_loss: 2.4383e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
            "Epoch 163/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0032 - mae: 0.0421 - val_loss: 2.5590e-04 - val_mae: 0.0129 - learning_rate: 0.0010\n",
            "Epoch 164/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0035 - mae: 0.0409 - val_loss: 2.6081e-04 - val_mae: 0.0131 - learning_rate: 0.0010\n",
            "Epoch 165/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0036 - mae: 0.0451 - val_loss: 2.5624e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
            "Epoch 166/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0434 - val_loss: 2.6028e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
            "Epoch 167/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0403 - val_loss: 2.6342e-04 - val_mae: 0.0127 - learning_rate: 0.0010\n",
            "Epoch 168/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0406 - val_loss: 2.5989e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
            "Epoch 169/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - mae: 0.0402 - val_loss: 2.5711e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
            "Epoch 170/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0027 - mae: 0.0398 - val_loss: 2.5014e-04 - val_mae: 0.0126 - learning_rate: 0.0010\n",
            "Epoch 171/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0410 - val_loss: 2.4557e-04 - val_mae: 0.0126 - learning_rate: 0.0010\n",
            "Epoch 172/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024 - mae: 0.0359 - val_loss: 2.4967e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
            "Epoch 173/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026 - mae: 0.0373 - val_loss: 2.5156e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
            "Epoch 174/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026 - mae: 0.0389 - val_loss: 2.4511e-04 - val_mae: 0.0126 - learning_rate: 0.0010\n",
            "Epoch 175/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0367 - val_loss: 2.5179e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
            "Epoch 176/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0021 - mae: 0.0355 - val_loss: 2.5996e-04 - val_mae: 0.0131 - learning_rate: 0.0010\n",
            "Epoch 177/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - mae: 0.0330 - val_loss: 2.6391e-04 - val_mae: 0.0132 - learning_rate: 0.0010\n",
            "Epoch 178/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0029 - mae: 0.0378 - val_loss: 2.4971e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
            "Epoch 179/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0026 - mae: 0.0368 - val_loss: 2.3152e-04 - val_mae: 0.0123 - learning_rate: 0.0010\n",
            "Epoch 180/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0362 - val_loss: 2.2291e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 181/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - mae: 0.0359 - val_loss: 2.2809e-04 - val_mae: 0.0123 - learning_rate: 0.0010\n",
            "Epoch 182/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0022 - mae: 0.0346 - val_loss: 2.4491e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
            "Epoch 183/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0024 - mae: 0.0362 - val_loss: 2.4808e-04 - val_mae: 0.0129 - learning_rate: 0.0010\n",
            "Epoch 184/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0021 - mae: 0.0343 - val_loss: 2.5600e-04 - val_mae: 0.0131 - learning_rate: 0.0010\n",
            "Epoch 185/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0022 - mae: 0.0343 - val_loss: 2.4455e-04 - val_mae: 0.0129 - learning_rate: 0.0010\n",
            "Epoch 186/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0022 - mae: 0.0345 - val_loss: 2.2961e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
            "Epoch 187/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 2.1974e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
            "Epoch 188/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0019 - mae: 0.0313 - val_loss: 2.1407e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 189/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0018 - mae: 0.0316 - val_loss: 2.0843e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 190/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0304 - val_loss: 2.1140e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
            "Epoch 191/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0021 - mae: 0.0336 - val_loss: 2.1181e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
            "Epoch 192/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 2.1408e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 193/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023 - mae: 0.0324 - val_loss: 2.0782e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
            "Epoch 194/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0316 - val_loss: 2.0293e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 195/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 2.0376e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 196/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0317 - val_loss: 2.0861e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
            "Epoch 197/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 2.1197e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 198/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0310 - val_loss: 2.1073e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 199/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 2.1578e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 200/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 2.2663e-04 - val_mae: 0.0124 - learning_rate: 0.0010\n",
            "Epoch 201/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 2.1690e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
            "Epoch 202/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0299 - val_loss: 2.1495e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
            "Epoch 203/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 2.2056e-04 - val_mae: 0.0123 - learning_rate: 0.0010\n",
            "Epoch 204/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 2.2453e-04 - val_mae: 0.0124 - learning_rate: 0.0010\n",
            "Epoch 205/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0330 - val_loss: 2.2666e-04 - val_mae: 0.0124 - learning_rate: 0.0010\n",
            "Epoch 206/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 2.1330e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
            "Epoch 207/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 2.0705e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
            "Epoch 208/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 2.0772e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
            "Epoch 209/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0268 - val_loss: 2.0858e-04 - val_mae: 0.0118 - learning_rate: 0.0010\n",
            "Epoch 210/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0258 - val_loss: 2.0121e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 211/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 1.9719e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 212/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0243 - val_loss: 1.9240e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 213/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 1.9122e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 214/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.8053e-04 - mae: 0.0240 - val_loss: 2.0072e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
            "Epoch 215/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 1.9574e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 216/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 1.9142e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 217/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.5200e-04 - mae: 0.0224 - val_loss: 1.9509e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 218/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0239 - val_loss: 1.9210e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
            "Epoch 219/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0247 - val_loss: 1.8494e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
            "Epoch 220/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0240 - val_loss: 1.8297e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 221/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 1.8894e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
            "Epoch 222/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0244 - val_loss: 1.9454e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
            "Epoch 223/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.3661e-04 - mae: 0.0236 - val_loss: 2.0418e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 224/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 1.9722e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 225/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.9537e-04 - mae: 0.0239 - val_loss: 1.8808e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
            "Epoch 226/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0237 - val_loss: 1.8142e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 227/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.8745e-04 - mae: 0.0223 - val_loss: 1.8443e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 228/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0259 - val_loss: 1.8959e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
            "Epoch 229/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 1.9094e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
            "Epoch 230/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0244 - val_loss: 1.9325e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
            "Epoch 231/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.3647e-04 - mae: 0.0218 - val_loss: 2.0616e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 232/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 2.0068e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 233/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0249 - val_loss: 1.8526e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 234/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.1018e-04 - mae: 0.0231 - val_loss: 1.7736e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
            "Epoch 235/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0251 - val_loss: 1.7860e-04 - val_mae: 0.0108 - learning_rate: 0.0010\n",
            "Epoch 236/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.5844e-04 - mae: 0.0240 - val_loss: 1.8014e-04 - val_mae: 0.0109 - learning_rate: 0.0010\n",
            "Epoch 237/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.7960e-04 - mae: 0.0202 - val_loss: 1.8548e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
            "Epoch 238/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.6978e-04 - mae: 0.0239 - val_loss: 1.9058e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
            "Epoch 239/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 1.9812e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 240/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.1433e-04 - mae: 0.0219 - val_loss: 2.0527e-04 - val_mae: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 241/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.0388e-04 - mae: 0.0220 - val_loss: 2.0006e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 242/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.8042e-04 - mae: 0.0206 - val_loss: 2.0009e-04 - val_mae: 0.0114 - learning_rate: 0.0010\n",
            "Epoch 243/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.4129e-04 - mae: 0.0224 - val_loss: 1.9793e-04 - val_mae: 0.0113 - learning_rate: 0.0010\n",
            "Epoch 244/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.6927e-04 - mae: 0.0206 - val_loss: 1.9153e-04 - val_mae: 0.0111 - learning_rate: 0.0010\n",
            "Epoch 245/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 6.9130e-04 - mae: 0.0201 - val_loss: 1.8397e-04 - val_mae: 0.0109 - learning_rate: 0.0010\n",
            "Epoch 246/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.6381e-04 - mae: 0.0215 - val_loss: 1.7233e-04 - val_mae: 0.0106 - learning_rate: 0.0010\n",
            "Epoch 247/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.6612e-04 - mae: 0.0223 - val_loss: 1.7351e-04 - val_mae: 0.0106 - learning_rate: 0.0010\n",
            "Epoch 248/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.7063e-04 - mae: 0.0216 - val_loss: 1.8096e-04 - val_mae: 0.0108 - learning_rate: 0.0010\n",
            "Epoch 249/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.3005e-04 - mae: 0.0215 - val_loss: 1.8781e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 250/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 8.3143e-04 - mae: 0.0225 - val_loss: 1.7472e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
            "Epoch 251/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.8278e-04 - mae: 0.0215 - val_loss: 1.6536e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
            "Epoch 252/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.8435e-04 - mae: 0.0222 - val_loss: 1.7114e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
            "Epoch 253/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.9475e-04 - mae: 0.0228 - val_loss: 1.8200e-04 - val_mae: 0.0108 - learning_rate: 0.0010\n",
            "Epoch 254/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.9376e-04 - mae: 0.0203 - val_loss: 1.8897e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 255/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.9397e-04 - mae: 0.0206 - val_loss: 1.8574e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 256/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.2313e-04 - mae: 0.0221 - val_loss: 1.8773e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 257/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.8168e-04 - mae: 0.0220 - val_loss: 1.8637e-04 - val_mae: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 258/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.7826e-04 - mae: 0.0182 - val_loss: 1.7729e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
            "Epoch 259/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.3558e-04 - mae: 0.0209 - val_loss: 1.5838e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
            "Epoch 260/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.8601e-04 - mae: 0.0219 - val_loss: 1.5680e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
            "Epoch 261/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.2267e-04 - mae: 0.0210 - val_loss: 1.6243e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
            "Epoch 262/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.8211e-04 - mae: 0.0196 - val_loss: 1.7176e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
            "Epoch 263/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.4896e-04 - mae: 0.0211 - val_loss: 1.8496e-04 - val_mae: 0.0109 - learning_rate: 0.0010\n",
            "Epoch 264/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.9579e-04 - mae: 0.0220 - val_loss: 1.8533e-04 - val_mae: 0.0109 - learning_rate: 0.0010\n",
            "Epoch 265/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.9460e-04 - mae: 0.0202 - val_loss: 1.7671e-04 - val_mae: 0.0106 - learning_rate: 0.0010\n",
            "Epoch 266/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.3079e-04 - mae: 0.0230 - val_loss: 1.6885e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
            "Epoch 267/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.9383e-04 - mae: 0.0202 - val_loss: 1.6110e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
            "Epoch 268/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.8314e-04 - mae: 0.0212 - val_loss: 1.6487e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
            "Epoch 269/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.9058e-04 - mae: 0.0218 - val_loss: 1.6244e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
            "Epoch 270/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.9093e-04 - mae: 0.0217 - val_loss: 1.6697e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
            "Epoch 271/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.4962e-04 - mae: 0.0195 - val_loss: 1.6590e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
            "Epoch 272/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.7787e-04 - mae: 0.0207 - val_loss: 1.7371e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
            "Epoch 273/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.5558e-04 - mae: 0.0188 - val_loss: 1.6771e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
            "Epoch 274/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.2580e-04 - mae: 0.0185 - val_loss: 1.6150e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
            "Epoch 275/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.7484e-04 - mae: 0.0180 - val_loss: 1.5962e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
            "Epoch 276/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.2589e-04 - mae: 0.0208 - val_loss: 1.5767e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
            "Epoch 277/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.6952e-04 - mae: 0.0188 - val_loss: 1.5101e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
            "Epoch 278/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.4089e-04 - mae: 0.0201 - val_loss: 1.4903e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
            "Epoch 279/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.0830e-04 - mae: 0.0192 - val_loss: 1.4593e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
            "Epoch 280/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.9020e-04 - mae: 0.0198 - val_loss: 1.4134e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
            "Epoch 281/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.0864e-04 - mae: 0.0193 - val_loss: 1.4011e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
            "Epoch 282/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.7488e-04 - mae: 0.0197 - val_loss: 1.3939e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 283/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3607e-04 - mae: 0.0197 - val_loss: 1.4706e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
            "Epoch 284/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.2168e-04 - mae: 0.0198 - val_loss: 1.5214e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
            "Epoch 285/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.3073e-04 - mae: 0.0210 - val_loss: 1.5849e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
            "Epoch 286/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.3197e-04 - mae: 0.0198 - val_loss: 1.5970e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
            "Epoch 287/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.7016e-04 - mae: 0.0202 - val_loss: 1.6297e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
            "Epoch 288/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.3924e-04 - mae: 0.0195 - val_loss: 1.6637e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
            "Epoch 289/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.2526e-04 - mae: 0.0197 - val_loss: 1.7105e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
            "Epoch 290/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.9316e-04 - mae: 0.0200 - val_loss: 1.6856e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
            "Epoch 291/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.7305e-04 - mae: 0.0181 - val_loss: 1.6648e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
            "Epoch 292/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5832e-04 - mae: 0.0190 - val_loss: 1.5606e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
            "Epoch 293/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.7211e-04 - mae: 0.0202 - val_loss: 1.6970e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
            "Epoch 294/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.4301e-04 - mae: 0.0193 - val_loss: 1.7252e-04 - val_mae: 0.0104 - learning_rate: 0.0010\n",
            "Epoch 295/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.3640e-04 - mae: 0.0189 - val_loss: 1.6916e-04 - val_mae: 0.0103 - learning_rate: 0.0010\n",
            "Epoch 296/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.6600e-04 - mae: 0.0201 - val_loss: 1.6381e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
            "Epoch 297/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.4148e-04 - mae: 0.0180 - val_loss: 1.6293e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
            "Epoch 298/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.6867e-04 - mae: 0.0182 - val_loss: 1.5744e-04 - val_mae: 0.0099 - learning_rate: 0.0010\n",
            "Epoch 299/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5405e-04 - mae: 0.0199 - val_loss: 1.4554e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
            "Epoch 300/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.6399e-04 - mae: 0.0181 - val_loss: 1.3897e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 301/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.4429e-04 - mae: 0.0186 - val_loss: 1.3679e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 302/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.5710e-04 - mae: 0.0198 - val_loss: 1.3935e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 303/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.9415e-04 - mae: 0.0186 - val_loss: 1.3984e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 304/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.5968e-04 - mae: 0.0185 - val_loss: 1.4300e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
            "Epoch 305/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.7559e-04 - mae: 0.0188 - val_loss: 1.4618e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
            "Epoch 306/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.3736e-04 - mae: 0.0183 - val_loss: 1.5204e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
            "Epoch 307/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.1811e-04 - mae: 0.0176 - val_loss: 1.4133e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 308/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.7623e-04 - mae: 0.0187 - val_loss: 1.3444e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
            "Epoch 309/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.6930e-04 - mae: 0.0192 - val_loss: 1.2942e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
            "Epoch 310/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.0204e-04 - mae: 0.0185 - val_loss: 1.3791e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 311/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.3912e-04 - mae: 0.0191 - val_loss: 1.3833e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 312/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.7836e-04 - mae: 0.0194 - val_loss: 1.3937e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 313/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.4089e-04 - mae: 0.0164 - val_loss: 1.5061e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
            "Epoch 314/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.2384e-04 - mae: 0.0196 - val_loss: 1.3722e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
            "Epoch 315/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.0488e-04 - mae: 0.0193 - val_loss: 1.3469e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
            "Epoch 316/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.9644e-04 - mae: 0.0180 - val_loss: 1.3141e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
            "Epoch 317/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.7173e-04 - mae: 0.0175 - val_loss: 1.4167e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 318/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.7665e-04 - mae: 0.0193 - val_loss: 1.3362e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
            "Epoch 319/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.9308e-04 - mae: 0.0191 - val_loss: 1.2956e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
            "Epoch 320/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.6942e-04 - mae: 0.0185 - val_loss: 1.3020e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
            "Epoch 321/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.6902e-04 - mae: 0.0170 - val_loss: 1.3056e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
            "Epoch 322/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7354e-04 - mae: 0.0178 - val_loss: 1.2866e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
            "Epoch 323/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.8437e-04 - mae: 0.0185 - val_loss: 1.3143e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
            "Epoch 324/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.5819e-04 - mae: 0.0187 - val_loss: 1.3322e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
            "Epoch 325/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.2512e-04 - mae: 0.0171 - val_loss: 1.3753e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 326/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.4170e-04 - mae: 0.0179 - val_loss: 1.3686e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 327/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7949e-04 - mae: 0.0184 - val_loss: 1.4554e-04 - val_mae: 0.0096 - learning_rate: 0.0010\n",
            "Epoch 328/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.1830e-04 - mae: 0.0170 - val_loss: 1.3952e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 329/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.0400e-04 - mae: 0.0175 - val_loss: 1.3647e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 330/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.8516e-04 - mae: 0.0184 - val_loss: 1.3606e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 331/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.7667e-04 - mae: 0.0170 - val_loss: 1.4033e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
            "Epoch 332/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.7732e-04 - mae: 0.0168 - val_loss: 1.5079e-04 - val_mae: 0.0097 - learning_rate: 0.0010\n",
            "Epoch 333/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.5428e-04 - mae: 0.0163 - val_loss: 1.3402e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
            "Epoch 334/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3115e-04 - mae: 0.0197 - val_loss: 1.2006e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 335/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.6771e-04 - mae: 0.0167 - val_loss: 1.1774e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 336/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5999e-04 - mae: 0.0170 - val_loss: 1.0998e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 337/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5431e-04 - mae: 0.0188 - val_loss: 1.0758e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 338/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1008e-04 - mae: 0.0186 - val_loss: 1.2109e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 339/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.1711e-04 - mae: 0.0212 - val_loss: 1.3382e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
            "Epoch 340/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.4450e-04 - mae: 0.0183 - val_loss: 1.3177e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
            "Epoch 341/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3334e-04 - mae: 0.0180 - val_loss: 1.2282e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 342/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7876e-04 - mae: 0.0177 - val_loss: 1.2272e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 343/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5695e-04 - mae: 0.0180 - val_loss: 1.1838e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 344/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.7124e-04 - mae: 0.0179 - val_loss: 1.1565e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 345/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.1853e-04 - mae: 0.0172 - val_loss: 1.0878e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 346/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.9094e-04 - mae: 0.0186 - val_loss: 1.1279e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 347/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.0993e-04 - mae: 0.0172 - val_loss: 1.1629e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 348/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.6002e-04 - mae: 0.0181 - val_loss: 1.1340e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 349/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.3008e-04 - mae: 0.0178 - val_loss: 1.1409e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 350/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.6413e-04 - mae: 0.0183 - val_loss: 1.1909e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 351/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.5673e-04 - mae: 0.0181 - val_loss: 1.1803e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 352/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.5378e-04 - mae: 0.0167 - val_loss: 1.1839e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 353/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.4046e-04 - mae: 0.0164 - val_loss: 1.1076e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 354/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.2149e-04 - mae: 0.0178 - val_loss: 1.1882e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 355/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.8608e-04 - mae: 0.0188 - val_loss: 1.2969e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
            "Epoch 356/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.1137e-04 - mae: 0.0171 - val_loss: 1.2504e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
            "Epoch 357/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.7546e-04 - mae: 0.0170 - val_loss: 1.1109e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 358/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.6135e-04 - mae: 0.0205 - val_loss: 1.1195e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 359/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.7285e-04 - mae: 0.0166 - val_loss: 1.1736e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 360/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3646e-04 - mae: 0.0179 - val_loss: 1.1865e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 361/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.7437e-04 - mae: 0.0168 - val_loss: 1.2843e-04 - val_mae: 0.0091 - learning_rate: 0.0010\n",
            "Epoch 362/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.0721e-04 - mae: 0.0179 - val_loss: 1.3019e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
            "Epoch 363/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.0115e-04 - mae: 0.0154 - val_loss: 1.1417e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 364/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.5908e-04 - mae: 0.0172 - val_loss: 1.0914e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 365/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.3735e-04 - mae: 0.0184 - val_loss: 1.1317e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 366/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3306e-04 - mae: 0.0193 - val_loss: 1.2275e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 367/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3781e-04 - mae: 0.0163 - val_loss: 1.2841e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 368/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.6616e-04 - mae: 0.0191 - val_loss: 1.3950e-04 - val_mae: 0.0092 - learning_rate: 0.0010\n",
            "Epoch 369/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0701e-04 - mae: 0.0150 - val_loss: 1.2739e-04 - val_mae: 0.0090 - learning_rate: 0.0010\n",
            "Epoch 370/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.9371e-04 - mae: 0.0182 - val_loss: 1.1253e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 371/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 5.0060e-04 - mae: 0.0171 - val_loss: 1.1490e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 372/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2862e-04 - mae: 0.0172 - val_loss: 1.2139e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 373/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.8781e-04 - mae: 0.0170 - val_loss: 1.1121e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 374/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.0535e-04 - mae: 0.0201 - val_loss: 1.0762e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 375/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 5.2093e-04 - mae: 0.0164 - val_loss: 1.2799e-04 - val_mae: 0.0089 - learning_rate: 0.0010\n",
            "Epoch 376/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.8533e-04 - mae: 0.0171 - val_loss: 1.2251e-04 - val_mae: 0.0086 - learning_rate: 0.0010\n",
            "Epoch 377/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.1533e-04 - mae: 0.0158 - val_loss: 1.2783e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 378/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.8158e-04 - mae: 0.0168 - val_loss: 1.1653e-04 - val_mae: 0.0085 - learning_rate: 0.0010\n",
            "Epoch 379/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.9910e-04 - mae: 0.0175 - val_loss: 1.0860e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 380/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.6671e-04 - mae: 0.0185 - val_loss: 1.0262e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
            "Epoch 381/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.4219e-04 - mae: 0.0171 - val_loss: 1.0680e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 382/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1201e-04 - mae: 0.0196 - val_loss: 1.1854e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 383/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.2732e-04 - mae: 0.0175 - val_loss: 1.2019e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 384/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.2696e-04 - mae: 0.0174 - val_loss: 1.2484e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 385/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.1259e-04 - mae: 0.0175 - val_loss: 1.2672e-04 - val_mae: 0.0088 - learning_rate: 0.0010\n",
            "Epoch 386/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.4306e-04 - mae: 0.0157 - val_loss: 1.0001e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
            "Epoch 387/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.3410e-04 - mae: 0.0179 - val_loss: 1.0556e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 388/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.5035e-04 - mae: 0.0178 - val_loss: 1.1050e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 389/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3824e-04 - mae: 0.0164 - val_loss: 1.0811e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 390/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.3088e-04 - mae: 0.0174 - val_loss: 1.0856e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 391/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.6715e-04 - mae: 0.0165 - val_loss: 1.2357e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 392/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.9044e-04 - mae: 0.0170 - val_loss: 1.1601e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 393/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.3720e-04 - mae: 0.0158 - val_loss: 1.0450e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
            "Epoch 394/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.2552e-04 - mae: 0.0177 - val_loss: 1.0430e-04 - val_mae: 0.0081 - learning_rate: 0.0010\n",
            "Epoch 395/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.6371e-04 - mae: 0.0165 - val_loss: 1.0616e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 396/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0641e-04 - mae: 0.0179 - val_loss: 1.0766e-04 - val_mae: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 397/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.8628e-04 - mae: 0.0162 - val_loss: 1.3530e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 398/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5147e-04 - mae: 0.0160 - val_loss: 1.1905e-04 - val_mae: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 399/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.1789e-04 - mae: 0.0185 - val_loss: 1.0306e-04 - val_mae: 0.0080 - learning_rate: 0.0010\n",
            "Epoch 400/400\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9567e-04 - mae: 0.0172 - val_loss: 1.0076e-04 - val_mae: 0.0079 - learning_rate: 0.0010\n",
            "Test loss, Test MAE: [0.00011625233310041949, 0.008205072954297066]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dae1e501da0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dae1e501da0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Actual Neutron Skin: 0.2270303992741831 | Predicted Neutron Skin: 0.22550000250339508 | Difference: 0.0015\n",
            "Actual Neutron Skin: 0.1354729845927596 | Predicted Neutron Skin: 0.1379999965429306 | Difference: 0.0026\n",
            "Actual Neutron Skin: 0.0903470032765678 | Predicted Neutron Skin: 0.11720000207424164 | Difference: 0.0269\n",
            "Actual Neutron Skin: 0.2320297410669333 | Predicted Neutron Skin: 0.23100000619888306 | Difference: 0.001\n",
            "Actual Neutron Skin: 0.0898044193275147 | Predicted Neutron Skin: 0.09260000288486481 | Difference: 0.0028\n",
            "Actual Neutron Skin: 0.1727664748477142 | Predicted Neutron Skin: 0.14910000562667847 | Difference: 0.0237\n",
            "Actual Neutron Skin: 0.187904173416337 | Predicted Neutron Skin: 0.17710000276565552 | Difference: 0.0108\n",
            "Actual Neutron Skin: 0.1535721719250395 | Predicted Neutron Skin: 0.14579999446868896 | Difference: 0.0078\n",
            "Actual Neutron Skin: 0.1499375368522086 | Predicted Neutron Skin: 0.15770000219345093 | Difference: 0.0078\n",
            "Actual Neutron Skin: 0.1427307279393858 | Predicted Neutron Skin: 0.12409999966621399 | Difference: 0.0186\n",
            "Actual Neutron Skin: 0.2415463415706477 | Predicted Neutron Skin: 0.24040000140666962 | Difference: 0.0011\n",
            "Actual Neutron Skin: 0.1158071325589372 | Predicted Neutron Skin: 0.12229999899864197 | Difference: 0.0065\n",
            "Actual Neutron Skin: 0.1024344891123353 | Predicted Neutron Skin: 0.1062999963760376 | Difference: 0.0038\n",
            "Actual Neutron Skin: 0.0889428586956843 | Predicted Neutron Skin: 0.0925000011920929 | Difference: 0.0036\n",
            "Actual Neutron Skin: 0.1642247139617847 | Predicted Neutron Skin: 0.15219999849796295 | Difference: 0.0121\n",
            "Actual Neutron Skin: 0.2187412740592866 | Predicted Neutron Skin: 0.22509999573230743 | Difference: 0.0064\n",
            "Actual Neutron Skin: 0.1226121015273593 | Predicted Neutron Skin: 0.13580000400543213 | Difference: 0.0132\n",
            "Actual Neutron Skin: 0.1116237647836522 | Predicted Neutron Skin: 0.1145000010728836 | Difference: 0.0029\n",
            "Actual Neutron Skin: 0.041158572210606 | Predicted Neutron Skin: 0.07440000027418137 | Difference: 0.0332\n",
            "Actual Neutron Skin: 0.0694436449155526 | Predicted Neutron Skin: 0.08139999955892563 | Difference: 0.0119\n",
            "Actual Neutron Skin: 0.1519885409158966 | Predicted Neutron Skin: 0.15520000457763672 | Difference: 0.0032\n",
            "Actual Neutron Skin: 0.1311585200467883 | Predicted Neutron Skin: 0.13830000162124634 | Difference: 0.0071\n",
            "Actual Neutron Skin: 0.2114906059360857 | Predicted Neutron Skin: 0.20730000734329224 | Difference: 0.0042\n",
            "Actual Neutron Skin: 0.1271761994075805 | Predicted Neutron Skin: 0.1185000017285347 | Difference: 0.0087\n",
            "Actual Neutron Skin: 0.2555995629945314 | Predicted Neutron Skin: 0.251800000667572 | Difference: 0.0038\n",
            "Actual Neutron Skin: 0.2174167963729516 | Predicted Neutron Skin: 0.21629999577999115 | Difference: 0.0011\n",
            "Actual Neutron Skin: 0.276131875711584 | Predicted Neutron Skin: 0.2671999931335449 | Difference: 0.009\n",
            "Actual Neutron Skin: 0.1303411852419102 | Predicted Neutron Skin: 0.13860000669956207 | Difference: 0.0083\n",
            "Actual Neutron Skin: 0.3076225964860528 | Predicted Neutron Skin: 0.2865999937057495 | Difference: 0.021\n",
            "Actual Neutron Skin: 0.1866203899939065 | Predicted Neutron Skin: 0.18389999866485596 | Difference: 0.0027\n",
            "Actual Neutron Skin: 0.1411926983509731 | Predicted Neutron Skin: 0.14990000426769257 | Difference: 0.0087\n",
            "Actual Neutron Skin: 0.1185785583976283 | Predicted Neutron Skin: 0.11659999936819077 | Difference: 0.002\n",
            "Actual Neutron Skin: 0.2693374135480291 | Predicted Neutron Skin: 0.2522999942302704 | Difference: 0.0171\n",
            "Actual Neutron Skin: 0.194031811811584 | Predicted Neutron Skin: 0.19529999792575836 | Difference: 0.0013\n",
            "Actual Neutron Skin: 0.2464096324968126 | Predicted Neutron Skin: 0.24819999933242798 | Difference: 0.0018\n",
            "Actual Neutron Skin: 0.141621898344253 | Predicted Neutron Skin: 0.14890000224113464 | Difference: 0.0073\n",
            "Actual Neutron Skin: 0.1290263577182878 | Predicted Neutron Skin: 0.1306000053882599 | Difference: 0.0016\n",
            "Actual Neutron Skin: 0.149798306340406 | Predicted Neutron Skin: 0.15770000219345093 | Difference: 0.0079\n",
            "Actual Neutron Skin: 0.1825622901680986 | Predicted Neutron Skin: 0.19020000100135803 | Difference: 0.0077\n",
            "Actual Neutron Skin: 0.111531211257397 | Predicted Neutron Skin: 0.12950000166893005 | Difference: 0.0179\n",
            "Actual Neutron Skin: 0.1256305551052453 | Predicted Neutron Skin: 0.13600000739097595 | Difference: 0.0104\n",
            "Actual Neutron Skin: 0.19516275797015 | Predicted Neutron Skin: 0.2003999948501587 | Difference: 0.0053\n",
            "Actual Neutron Skin: 0.1647452407245194 | Predicted Neutron Skin: 0.16820000112056732 | Difference: 0.0034\n",
            "Actual Neutron Skin: 0.1506572461174056 | Predicted Neutron Skin: 0.14650000631809235 | Difference: 0.0042\n",
            "Actual Neutron Skin: 0.1942373411278755 | Predicted Neutron Skin: 0.19709999859333038 | Difference: 0.0029\n",
            "Actual Neutron Skin: 0.1442067326645013 | Predicted Neutron Skin: 0.14589999616146088 | Difference: 0.0017\n",
            "Actual Neutron Skin: 0.224175827773086 | Predicted Neutron Skin: 0.23109999299049377 | Difference: 0.0069\n",
            "Actual Neutron Skin: 0.2729001889829513 | Predicted Neutron Skin: 0.2531999945640564 | Difference: 0.0197\n",
            "Actual Neutron Skin: 0.2024159867037279 | Predicted Neutron Skin: 0.21040000021457672 | Difference: 0.008\n",
            "Actual Neutron Skin: 0.2931618270713312 | Predicted Neutron Skin: 0.2750999927520752 | Difference: 0.018\n",
            "Actual Neutron Skin: 0.2153366789740722 | Predicted Neutron Skin: 0.21629999577999115 | Difference: 0.0009\n",
            "Actual Neutron Skin: 0.186725970063553 | Predicted Neutron Skin: 0.17960000038146973 | Difference: 0.0072\n",
            "Actual Neutron Skin: 0.2186419023642867 | Predicted Neutron Skin: 0.21160000562667847 | Difference: 0.007\n",
            "Actual Neutron Skin: 0.2483807904068852 | Predicted Neutron Skin: 0.24410000443458557 | Difference: 0.0043\n",
            "Actual Neutron Skin: 0.0493045963123748 | Predicted Neutron Skin: 0.07649999856948853 | Difference: 0.0271\n",
            "Actual Neutron Skin: 0.136635015854052 | Predicted Neutron Skin: 0.15049999952316284 | Difference: 0.0139\n",
            "Actual Neutron Skin: 0.0814391686299619 | Predicted Neutron Skin: 0.09920000284910202 | Difference: 0.0178\n",
            "Actual Neutron Skin: 0.2137734471350765 | Predicted Neutron Skin: 0.2159000039100647 | Difference: 0.0021\n",
            "Actual Neutron Skin: 0.1620317301645184 | Predicted Neutron Skin: 0.1534000039100647 | Difference: 0.0086\n",
            "Actual Neutron Skin: 0.1030610397005326 | Predicted Neutron Skin: 0.10090000182390213 | Difference: 0.0021\n",
            "Actual Neutron Skin: 0.0712637824408621 | Predicted Neutron Skin: 0.0869000032544136 | Difference: 0.0157\n",
            "Actual Neutron Skin: 0.1486192869047592 | Predicted Neutron Skin: 0.15289999544620514 | Difference: 0.0043\n",
            "Actual Neutron Skin: 0.1325721111840673 | Predicted Neutron Skin: 0.13600000739097595 | Difference: 0.0034\n",
            "Actual Neutron Skin: 0.1788928920470312 | Predicted Neutron Skin: 0.18700000643730164 | Difference: 0.0081\n",
            "Actual Neutron Skin: 0.2126468640229947 | Predicted Neutron Skin: 0.20489999651908875 | Difference: 0.0078\n",
            "Actual Neutron Skin: 0.1447216804571922 | Predicted Neutron Skin: 0.14900000393390656 | Difference: 0.0043\n",
            "Actual Neutron Skin: 0.1606438618250965 | Predicted Neutron Skin: 0.14910000562667847 | Difference: 0.0116\n",
            "Actual Neutron Skin: 0.2557027733182508 | Predicted Neutron Skin: 0.24549999833106995 | Difference: 0.0102\n",
            "Actual Neutron Skin: 0.2248932731849988 | Predicted Neutron Skin: 0.21770000457763672 | Difference: 0.0072\n",
            "Actual Neutron Skin: 0.1494511646994303 | Predicted Neutron Skin: 0.14830000698566437 | Difference: 0.0012\n",
            "Actual Neutron Skin: 0.1441589521915658 | Predicted Neutron Skin: 0.1476999968290329 | Difference: 0.0036\n",
            "Actual Neutron Skin: 0.1642124656763409 | Predicted Neutron Skin: 0.17020000517368317 | Difference: 0.006\n",
            "Actual Neutron Skin: 0.1550511436668189 | Predicted Neutron Skin: 0.14740000665187836 | Difference: 0.0076\n",
            "Actual Neutron Skin: 0.1766633008383384 | Predicted Neutron Skin: 0.1657000035047531 | Difference: 0.011\n",
            "Actual Neutron Skin: 0.2323546611476229 | Predicted Neutron Skin: 0.23350000381469727 | Difference: 0.0011\n",
            "Actual Neutron Skin: 0.069467670120215 | Predicted Neutron Skin: 0.08269999921321869 | Difference: 0.0132\n",
            "Actual Neutron Skin: 0.1459285258914702 | Predicted Neutron Skin: 0.15530000627040863 | Difference: 0.0094\n",
            "Actual Neutron Skin: 0.2225016984626547 | Predicted Neutron Skin: 0.21050000190734863 | Difference: 0.012\n",
            "Actual Neutron Skin: 0.1510279211574015 | Predicted Neutron Skin: 0.14090000092983246 | Difference: 0.0101\n",
            "Actual Neutron Skin: 0.2433040946573721 | Predicted Neutron Skin: 0.23199999332427979 | Difference: 0.0113\n",
            "Actual Neutron Skin: 0.0760883489385676 | Predicted Neutron Skin: 0.10649999976158142 | Difference: 0.0304\n",
            "Actual Neutron Skin: 0.2014048731602701 | Predicted Neutron Skin: 0.19979999959468842 | Difference: 0.0016\n",
            "Actual Neutron Skin: 0.142764719176814 | Predicted Neutron Skin: 0.1500999927520752 | Difference: 0.0074\n",
            "Actual Neutron Skin: 0.2683556221313926 | Predicted Neutron Skin: 0.26100000739097595 | Difference: 0.0073\n",
            "Actual Neutron Skin: 0.1416612699916166 | Predicted Neutron Skin: 0.14589999616146088 | Difference: 0.0042\n",
            "Actual Neutron Skin: 0.1572852065938987 | Predicted Neutron Skin: 0.16300000250339508 | Difference: 0.0057\n",
            "Actual Neutron Skin: 0.0944230580900011 | Predicted Neutron Skin: 0.09440000355243683 | Difference: 0.0\n",
            "Actual Neutron Skin: 0.2655494070402946 | Predicted Neutron Skin: 0.263700008392334 | Difference: 0.0018\n",
            "Actual Neutron Skin: 0.2347160303120701 | Predicted Neutron Skin: 0.23360000550746918 | Difference: 0.0011\n",
            "Actual Neutron Skin: 0.2242854427449878 | Predicted Neutron Skin: 0.22290000319480896 | Difference: 0.0013\n",
            "Actual Neutron Skin: 0.1630996077952387 | Predicted Neutron Skin: 0.1559000015258789 | Difference: 0.0072\n",
            "Actual Neutron Skin: 0.1396829146352171 | Predicted Neutron Skin: 0.1468999981880188 | Difference: 0.0072\n",
            "Actual Neutron Skin: 0.1305766357431274 | Predicted Neutron Skin: 0.11909999698400497 | Difference: 0.0115\n",
            "Actual Neutron Skin: 0.1884618409103746 | Predicted Neutron Skin: 0.1964000016450882 | Difference: 0.0079\n",
            "Actual Neutron Skin: 0.2736120419752371 | Predicted Neutron Skin: 0.2669999897480011 | Difference: 0.0067\n",
            "Actual Neutron Skin: 0.1420147821711502 | Predicted Neutron Skin: 0.14390000700950623 | Difference: 0.0018\n",
            "Actual Neutron Skin: 0.2478224347927428 | Predicted Neutron Skin: 0.23919999599456787 | Difference: 0.0086\n",
            "Actual Neutron Skin: 0.1858097710859814 | Predicted Neutron Skin: 0.18410000205039978 | Difference: 0.0017\n",
            "Actual Neutron Skin: 0.2336942643153499 | Predicted Neutron Skin: 0.23589999973773956 | Difference: 0.0022\n",
            "Actual Neutron Skin: 0.1268563798631322 | Predicted Neutron Skin: 0.1388999968767166 | Difference: 0.0121\n",
            "Actual Neutron Skin: 0.1391447105523651 | Predicted Neutron Skin: 0.1251000016927719 | Difference: 0.014\n",
            "Actual Neutron Skin: 0.1715470010861077 | Predicted Neutron Skin: 0.17159999907016754 | Difference: 0.0001\n",
            "Actual Neutron Skin: 0.1821890717528596 | Predicted Neutron Skin: 0.1881999969482422 | Difference: 0.006\n",
            "Actual Neutron Skin: 0.1794673733720336 | Predicted Neutron Skin: 0.16130000352859497 | Difference: 0.0182\n",
            "Actual Neutron Skin: 0.176704447218128 | Predicted Neutron Skin: 0.1761000007390976 | Difference: 0.0006\n",
            "Actual Neutron Skin: 0.1709496141424427 | Predicted Neutron Skin: 0.14910000562667847 | Difference: 0.0219\n",
            "Actual Neutron Skin: 0.0786251498598775 | Predicted Neutron Skin: 0.08990000188350677 | Difference: 0.0113\n",
            "Actual Neutron Skin: 0.2533658923736729 | Predicted Neutron Skin: 0.25 | Difference: 0.0034\n",
            "Actual Neutron Skin: 0.1557501203473994 | Predicted Neutron Skin: 0.16089999675750732 | Difference: 0.0052\n",
            "Actual Neutron Skin: 0.0419859039535523 | Predicted Neutron Skin: 0.07739999890327454 | Difference: 0.0354\n",
            "Actual Neutron Skin: 0.2316554064800102 | Predicted Neutron Skin: 0.23319999873638153 | Difference: 0.0016\n",
            "Actual Neutron Skin: 0.1383490919296789 | Predicted Neutron Skin: 0.1257999986410141 | Difference: 0.0126\n",
            "Actual Neutron Skin: 0.273280908583572 | Predicted Neutron Skin: 0.2671999931335449 | Difference: 0.0061\n",
            "Actual Neutron Skin: 0.1256333666348502 | Predicted Neutron Skin: 0.1356000006198883 | Difference: 0.01\n",
            "Actual Neutron Skin: 0.2177909078670125 | Predicted Neutron Skin: 0.219200000166893 | Difference: 0.0014\n",
            "Actual Neutron Skin: 0.1572671154406798 | Predicted Neutron Skin: 0.14810000360012054 | Difference: 0.0091\n",
            "Actual Neutron Skin: 0.0945870218013821 | Predicted Neutron Skin: 0.10450000315904617 | Difference: 0.0099\n",
            "Actual Neutron Skin: 0.2678708987337629 | Predicted Neutron Skin: 0.26409998536109924 | Difference: 0.0037\n",
            "Actual Neutron Skin: 0.2322272435608215 | Predicted Neutron Skin: 0.23240000009536743 | Difference: 0.0002\n",
            "Actual Neutron Skin: 0.2825427324276872 | Predicted Neutron Skin: 0.2644999921321869 | Difference: 0.018\n",
            "Actual Neutron Skin: 0.178123435087875 | Predicted Neutron Skin: 0.18160000443458557 | Difference: 0.0034\n",
            "Actual Neutron Skin: 0.3048356093135616 | Predicted Neutron Skin: 0.28610000014305115 | Difference: 0.0188\n",
            "Actual Neutron Skin: 0.1848916012639839 | Predicted Neutron Skin: 0.18029999732971191 | Difference: 0.0046\n",
            "Actual Neutron Skin: 0.1300735150304774 | Predicted Neutron Skin: 0.14229999482631683 | Difference: 0.0122\n",
            "Actual Neutron Skin: 0.273208341966464 | Predicted Neutron Skin: 0.2621000111103058 | Difference: 0.0111\n",
            "Actual Neutron Skin: 0.2913531820117135 | Predicted Neutron Skin: 0.2791999876499176 | Difference: 0.0122\n",
            "Actual Neutron Skin: 0.1478917234930066 | Predicted Neutron Skin: 0.1559000015258789 | Difference: 0.0081\n",
            "Actual Neutron Skin: 0.303356383047795 | Predicted Neutron Skin: 0.29580000042915344 | Difference: 0.0075\n",
            "Actual Neutron Skin: 0.1990853416762496 | Predicted Neutron Skin: 0.19910000264644623 | Difference: 0.0\n",
            "Actual Neutron Skin: 0.2261957722722871 | Predicted Neutron Skin: 0.22769999504089355 | Difference: 0.0015\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!pip install keras-tuner -q\\nimport keras_tuner as kt\\n\\ndef model_builder(hp):\\n    \"\"\"Builds a Keras model with tunable hyperparameters.\"\"\"\\n    model = tf.keras.Sequential()\\n\\n    # Tunable number of units in the first hidden layer\\n    hp_units_1 = hp.Int(\\'units_1\\', min_value=32, max_value=512, step=32)\\n    model.add(tf.keras.layers.Dense(units=hp_units_1, activation=\\'relu\\', input_dim=3))\\n    model.add(tf.keras.layers.BatchNormalization())  # Batch Normalization\\n    model.add(tf.keras.layers.Dropout(rate=hp.Float(\\'dropout_1\\', min_value=0.2, max_value=0.7, step=0.1)))  # Dropout\\n\\n    # Tunable number of units in the second hidden layer\\n    hp_units_2 = hp.Int(\\'units_2\\', min_value=32, max_value=206, step=32)\\n    model.add(tf.keras.layers.Dense(units=hp_units_2, activation=\\'relu\\'))\\n    model.add(tf.keras.layers.BatchNormalization())  # Batch Normalization\\n    model.add(tf.keras.layers.Dropout(rate=hp.Float(\\'dropout_2\\', min_value=0.2, max_value=0.5, step=0.1)))  # Dropout\\n\\n    # Third hidden layer with tunable units\\n    hp_units_3 = hp.Int(\\'units_3\\', min_value=16, max_value=206, step=16)\\n    model.add(tf.keras.layers.Dense(units=hp_units_3, activation=\\'relu\\'))\\n    model.add(tf.keras.layers.BatchNormalization())  # Batch Normalization\\n    model.add(tf.keras.layers.Dropout(rate=hp.Float(\\'dropout_3\\', min_value=0.2, max_value=0.4, step=0.1)))  # Dropout\\n\\n\\n\\n    model.add(tf.keras.layers.Dense(1, activation=\\'linear\\'))  # Output layer\\n\\n    # Tunable learning rate\\n    hp_learning_rate = hp.Choice(\\'learning_rate\\', values=[1e-2, 1e-3, 1e-4])\\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\\n                  loss=\\'mean_squared_error\\',\\n                  metrics=[\\'mae\\'])\\n\\n    return model\\n\\n# Create the tuner\\ntuner = kt.RandomSearch(model_builder,\\n                        objective=\\'val_mae\\',\\n                        max_trials=150,\\n                        executions_per_trial=4,\\n                        directory=\\'my_dir\\',\\n                        project_name=\\'my_project\\')\\n\\n# Search for the best hyperparameters\\ntuner.search(x_train, y_train, epochs=275, validation_split=0.2)\\n\\n# Get the best model\\nbest_model = tuner.get_best_models(num_models=1)[0]\\n\\n# Evaluate the best model\\nresults = best_model.evaluate(x_test, y_test, verbose=0)\\nprint(\\'Test loss, Test MAE:\\', results)\\n\\n# ... Use best_model for predictions ...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Load the dataset (adjust delimiter if needed, assuming space-separated for this example)\n",
        "file_path = '_newmatter_table_nskins.csv'\n",
        "data = pd.read_csv(file_path, delimiter=',')  # Adjust delimiter if needed\n",
        "\n",
        "# Check the first few rows to ensure it's loaded correctly\n",
        "print(data.head())\n",
        "print(data.columns)\n",
        "\n",
        "# Extract the first three columns (J, L, K_sym) as input features\n",
        "x_data1 = data[['J', 'L', 'Ksym']].values\n",
        "\n",
        "# Extract the neutron skin of Pb-208 (34th column) as the target output\n",
        "y_data = data['drPb208'].values # Column 34 is the neutron skin of Pb-208\n",
        "\n",
        "# Normalize the input features\n",
        "scaler = StandardScaler()\n",
        "x_data = scaler.fit_transform(x_data1)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Checking the shape of the data\n",
        "print(\"Feature matrix (x_train):\", x_train.shape)\n",
        "print(\"Target matrix (y_train):\", y_train.shape)\n",
        "print(\"Feature matrix (x_test):\", x_test.shape)\n",
        "print(\"Target matrix (y_test):\", y_test.shape)\n",
        "\n",
        "# Building the Sequential neural network model for regression\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(416, input_dim=3, activation='relu'), #Input layer\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #hidden layer 1\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(16, activation='relu'), #hidden layer 2\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation='linear')  # Linear activation for regression (single output)\n",
        "])\n",
        "\n",
        "# Compile the model for regression\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mae'])\n",
        "\n",
        "# Callbacks: Early Stopping and Learning Rate Scheduler\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=400, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=400, factor=0.01, min_lr=1e-6)\n",
        "\n",
        "# Training the model with training data\n",
        "history = model.fit(x_train, y_train, epochs=400,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "# Evaluate the model on test data\n",
        "results = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss, Test MAE:', results)\n",
        "\n",
        "# Visualization of Training and Validation Loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plotting Training and Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
        "plt.title('Training and Validation Loss', fontsize=14)\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plotting Training and Validation MAE (Mean Absolute Error)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['mae'], label='Training MAE', color='blue')\n",
        "plt.plot(history.history['val_mae'], label='Validation MAE', color='orange')\n",
        "plt.title('Training and Validation MAE', fontsize=14)\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.ylabel('MAE', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.suptitle(\"Model Training Performance\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Get predictions from the model on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Round the predicted values and calculate the absolute differences with actual values\n",
        "differences = np.abs(y_test - y_pred.flatten())\n",
        "y_pred_rounded = np.round(y_pred.flatten(), 4)\n",
        "differences_rounded = np.round(differences, 4)\n",
        "\n",
        "# Print the actual, predicted values, and their differences\n",
        "for actual, predicted, diff in zip(y_test, y_pred_rounded, differences_rounded):\n",
        "    print(f\"Actual Neutron Skin: {actual} | Predicted Neutron Skin: {predicted} | Difference: {diff}\")\n",
        "\n",
        "# Print the summary of the model to see the architecture and parameters\n",
        "#model.summary()\n",
        "\n",
        "\n",
        "#Saving the entire NN\n",
        "#model.save('Pingu.h5')\n",
        "\n",
        "#very inificient way of finding better layer valuies below\n",
        "#I need to understand it better, but keras tools allows for the NN to be repeatedly ran wile it selects random values for the neurons and i specifically made it focus on the MAE and loss error reduction.\n",
        "\n",
        "'''\n",
        "!pip install keras-tuner -q\n",
        "import keras_tuner as kt\n",
        "\n",
        "def model_builder(hp):\n",
        "    \"\"\"Builds a Keras model with tunable hyperparameters.\"\"\"\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Tunable number of units in the first hidden layer\n",
        "    hp_units_1 = hp.Int('units_1', min_value=32, max_value=512, step=32)\n",
        "    model.add(tf.keras.layers.Dense(units=hp_units_1, activation='relu', input_dim=3))\n",
        "    model.add(tf.keras.layers.BatchNormalization())  # Batch Normalization\n",
        "    model.add(tf.keras.layers.Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.7, step=0.1)))  # Dropout\n",
        "\n",
        "    # Tunable number of units in the second hidden layer\n",
        "    hp_units_2 = hp.Int('units_2', min_value=32, max_value=206, step=32)\n",
        "    model.add(tf.keras.layers.Dense(units=hp_units_2, activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())  # Batch Normalization\n",
        "    model.add(tf.keras.layers.Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))  # Dropout\n",
        "\n",
        "    # Third hidden layer with tunable units\n",
        "    hp_units_3 = hp.Int('units_3', min_value=16, max_value=206, step=16)\n",
        "    model.add(tf.keras.layers.Dense(units=hp_units_3, activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())  # Batch Normalization\n",
        "    model.add(tf.keras.layers.Dropout(rate=hp.Float('dropout_3', min_value=0.2, max_value=0.4, step=0.1)))  # Dropout\n",
        "\n",
        "\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1, activation='linear'))  # Output layer\n",
        "\n",
        "    # Tunable learning rate\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the tuner\n",
        "tuner = kt.RandomSearch(model_builder,\n",
        "                        objective='val_mae',\n",
        "                        max_trials=150,\n",
        "                        executions_per_trial=4,\n",
        "                        directory='my_dir',\n",
        "                        project_name='my_project')\n",
        "\n",
        "# Search for the best hyperparameters\n",
        "tuner.search(x_train, y_train, epochs=275, validation_split=0.2)\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate the best model\n",
        "results = best_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss, Test MAE:', results)\n",
        "\n",
        "# ... Use best_model for predictions ...'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G66EL_jfZAoM"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9Ah84dQLUGOB53aNjjLrJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}